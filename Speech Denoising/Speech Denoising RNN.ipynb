{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14361582112064692383\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14819619636\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 4032390799241720485\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:09:00.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files, valid_files, test_files, N_V_trans, S_V_trans, X_V_trans, N_trans, S_trans, X_trans = [[] for i in range(9)]\n",
    "files = os.listdir('/N/u/pmadinen/Assignment 2/tr')\n",
    "valid_files = os.listdir('/N/u/pmadinen/Assignment 2/v')\n",
    "files.sort()\n",
    "valid_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing audio signals and trasformig them into spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1200):\n",
    "    s, sr=librosa.load('/N/u/pmadinen/Assignment 2/tr/' + files[i], sr=None)\n",
    "    N_trans.append(np.transpose(np.abs(librosa.stft(s, n_fft=1024, hop_length=512))))\n",
    "\n",
    "    s, sr=librosa.load('/N/u/pmadinen/Assignment 2/tr/' + files[i + 1200], sr=None)\n",
    "    S_trans.append(np.transpose(np.abs(librosa.stft(s, n_fft=1024, hop_length=512))))\n",
    "    \n",
    "    s, sr=librosa.load('/N/u/pmadinen/Assignment 2/tr/' + files[i + 2400], sr=None)\n",
    "    X_trans.append(np.transpose(np.abs(librosa.stft(s, n_fft=1024, hop_length=512))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1200):\n",
    "    s, sr=librosa.load('/N/u/pmadinen/Assignment 2/v/' + valid_files[i], sr=None)\n",
    "    N_V_trans.append(np.transpose(np.abs(librosa.stft(s, n_fft=1024, hop_length=512))))\n",
    "\n",
    "    s, sr=librosa.load('/N/u/pmadinen/Assignment 2/v/' + valid_files[i + 1200], sr=None)\n",
    "    S_V_trans.append(np.transpose(np.abs(librosa.stft(s, n_fft=1024, hop_length=512))))\n",
    "    \n",
    "    s, sr=librosa.load('/N/u/pmadinen/Assignment 2/v/' + valid_files[i + 2400], sr=None)\n",
    "    X_V_trans.append(np.transpose(np.abs(librosa.stft(s, n_fft=1024, hop_length=512))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    }
   ],
   "source": [
    "max = X_trans[i].shape[0]\n",
    "for i in range(len(X_trans)):\n",
    "    if max <= X_trans[i].shape[0] :\n",
    "        max = X_trans[i].shape[0]\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since the maximum number of row for a signal generated is 178, preparing the IBM matrices with order 178 * 513\n",
    "M_trans = np.zeros((1200, 178, 513))\n",
    "X_input = np.zeros((1200, 178, 513))\n",
    "\n",
    "for i in range(len(X_trans)):\n",
    "    for j in range(len(X_trans[i])):\n",
    "        for k in range(len(X_trans[i][j])):\n",
    "            X_input[i][j][k] = X_trans[i][j][k]\n",
    "            if S_trans[i][j][k] > N_trans[i][j][k]:\n",
    "                M_trans[i][j][k] = 1\n",
    "            else:\n",
    "                M_trans[i][j][k] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_V_trans = np.zeros((1200, 178, 513))\n",
    "X_V_input = np.zeros((1200, 178, 513))\n",
    "\n",
    "for i in range(len(X_V_trans)):\n",
    "    for j in range(len(X_V_trans[i])):\n",
    "        for k in range(len(X_V_trans[i][j])):\n",
    "            X_V_input[i][j][k] = X_V_trans[i][j][k]\n",
    "            if S_V_trans[i][j][k] > N_V_trans[i][j][k]:\n",
    "                M_V_trans[i][j][k] = 1\n",
    "            else:\n",
    "                M_V_trans[i][j][k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_steps = 10\n",
    "Neurons = 128\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "hold_prob = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_trans = M_trans.reshape(-1, time_steps, 513)\n",
    "X_input = X_input.reshape(-1, time_steps, 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_V_trans = M_V_trans.reshape(-1, time_steps, 513)\n",
    "X_V_input = X_V_input.reshape(-1, time_steps, 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21360, 10, 513) (21360, 10, 513) (21360, 10, 513) (21360, 10, 513)\n"
     ]
    }
   ],
   "source": [
    "print(M_trans.shape, X_input.shape, M_V_trans.shape, X_V_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a function that returns random batches of rows for training\n",
    "\n",
    "def Batching(x, y, batch_size, shuffle = False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(x.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for idx in range(0, x.shape[0] - batch_size + 1, batch_size):\n",
    "        if shuffle:\n",
    "            batch = indices[idx: idx + batch_size]\n",
    "        else:\n",
    "            batch = slice(idx, idx + batch_size)\n",
    "        yield x[batch], y[batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the place holders\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, None, 513])\n",
    "y = tf.placeholder(tf.float32, [None, None, 513])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the RNN layer\n",
    "\n",
    "RNN = tf.contrib.rnn.OutputProjectionWrapper(tf.contrib.rnn.BasicLSTMCell(num_units = Neurons, activation = tf.nn.sigmoid),\n",
    "    output_size = 513)\n",
    "RNN = tf.nn.rnn_cell.DropoutWrapper(RNN, output_keep_prob = hold_prob)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(RNN, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the loss\n",
    "\n",
    "MSE = tf.reduce_mean(tf.pow(outputs - y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the Optimizer Function\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train = optimizer.minimize(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the Session\n",
    "\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the Session\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch # 0\n",
      "MSE = 0.11759767681360245\n",
      "\n",
      "\n",
      "Currently on Epoch # 6\n",
      "MSE = 0.09419693797826767\n",
      "\n",
      "\n",
      "Currently on Epoch # 12\n",
      "MSE = 0.08864549547433853\n",
      "\n",
      "\n",
      "Currently on Epoch # 18\n",
      "MSE = 0.084555983543396\n",
      "\n",
      "\n",
      "Currently on Epoch # 24\n",
      "MSE = 0.08415083587169647\n",
      "\n",
      "\n",
      "Currently on Epoch # 30\n",
      "MSE = 0.08239462971687317\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = 30\n",
    "\n",
    "for i in range(iterations + 1):\n",
    "\n",
    "    for batch in Batching(X_input, M_trans, batch_size, shuffle = True):\n",
    "         batch_X , batch_Y = batch\n",
    "    \n",
    "         sess.run(train, feed_dict={X: batch_X, y: batch_Y})\n",
    "\n",
    "    if i% 6 == 0 :\n",
    "        loss = sess.run(MSE, feed_dict={X: X_V_input, y: M_V_trans})\n",
    "\n",
    "        print(\"Currently on Epoch # {}\".format(i))\n",
    "        print(\"MSE = {}\".format(loss))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing test signals, cleaning them and reconverting them back to auido signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = os.listdir('/N/u/pmadinen/Assignment 2/te')\n",
    "test_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_files)):\n",
    "    s, sr = librosa.load('/N/u/pmadinen/Assignment 2/te/' + test_files[i], sr=None)\n",
    "    test_complex = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "    test = np.transpose(np.abs(test_complex))\n",
    "    test = test.reshape(1, -1, 513)\n",
    "    test_clean_trans = sess.run(outputs, feed_dict={X: test})\n",
    "    test_clean_reshaped = test_clean_trans.reshape(-1, 513) \n",
    "    test_clean = np.transpose(test_clean_reshaped)\n",
    "    test_phase = np.divide(test_complex, np.abs(test_complex))\n",
    "    test_clean_phase = np.multiply(test_clean, test_phase)\n",
    "    sh_T1 = librosa.istft(test_clean_phase,hop_length=512)\n",
    "    librosa.output.write_wav('/N/u/pmadinen/Assignment 2/Clean Test Files/tex_s_recons_' + str(i) + '.wav', sh_T1, sr)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zf = zipfile.ZipFile(\"Clean Files.zip\", \"w\")\n",
    "for dirname, subdirs, files in os.walk(\"/N/u/pmadinen/Assignment 2/Clean Test Files\"):\n",
    "    zf.write(dirname)\n",
    "    for filename in files:\n",
    "        zf.write(os.path.join(dirname, filename))\n",
    "zf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
