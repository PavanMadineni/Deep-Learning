{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "t1, sr=librosa.load('test_x_01.wav', sr=None)\n",
    "T1=librosa.stft(t1, n_fft=1024, hop_length=512)\n",
    "t2, sr=librosa.load('test_x_02.wav', sr=None)\n",
    "T2=librosa.stft(t2, n_fft=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 2459) (513, 2459) (513, 142) (513, 380)\n"
     ]
    }
   ],
   "source": [
    "print(S.shape, X.shape, T1.shape, T2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_mod = np.abs(S)\n",
    "Dirty_mod = np.abs(X)\n",
    "T1_mod = np.abs(T1)\n",
    "T2_mod = np.abs(T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 2459) (513, 2459) (513, 142) (513, 380)\n"
     ]
    }
   ],
   "source": [
    "print(Clean_mod.shape, Dirty_mod.shape, T1_mod.shape, T2_mod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_Trans = np.transpose(Clean_mod)\n",
    "Dirty_Trans = Dirty_mod.transpose()\n",
    "T1_Dirty_Trans = T1_mod.transpose()\n",
    "T2_Dirty_Trans = T2_mod.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2459, 513) (2459, 513) (142, 513) (380, 513)\n"
     ]
    }
   ],
   "source": [
    "print(Clean_Trans.shape, Dirty_Trans.shape, T1_Dirty_Trans.shape, T2_Dirty_Trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Place Holders\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 513])\n",
    "\n",
    "Y_true = tf.placeholder(tf.float32, shape = [None, 513])\n",
    "\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Hidden Layers\n",
    "\n",
    "HL1 = 670\n",
    "\n",
    "HL2 = 670\n",
    "\n",
    "OL = 513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the weights and bias for the five layers\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([513, HL1], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([HL1]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([HL1, HL2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([HL2]))\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([HL2, OL], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([OL]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the activation function for each layer\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1_dropout = tf.nn.dropout(L1, hold_prob)\n",
    "\n",
    "L2 = tf.nn.relu(tf.matmul(L1_dropout, W2) + b2)\n",
    "L2_dropout = tf.nn.dropout(L2, hold_prob)\n",
    "\n",
    "Y_logits = tf.matmul(L2_dropout, W3) + b3\n",
    "\n",
    "Y_pred = tf.nn.sigmoid(Y_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Loss Function\n",
    "\n",
    "MSE = tf.reduce_mean(tf.pow(Y_true - Y_pred, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the optimizer function\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "train = optimizer.minimize(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Session\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that returns random batches of rows for training\n",
    "\n",
    "def Batching(x, y, batch_size, shuffle = False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(x.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for idx in range(0, x.shape[0] - batch_size + 1, batch_size):\n",
    "        if shuffle:\n",
    "            batch = indices[idx: idx + batch_size]\n",
    "        else:\n",
    "            batch = slice(idx, idx + batch_size)\n",
    "        yield x[batch], y[batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch # 0\n",
      "Training Loss = 0.076544851064682\n",
      "\n",
      "\n",
      "Currently on Epoch # 1000\n",
      "Training Loss = 0.05235903337597847\n",
      "\n",
      "\n",
      "Currently on Epoch # 2000\n",
      "Training Loss = 0.04080304875969887\n",
      "\n",
      "\n",
      "Currently on Epoch # 3000\n",
      "Training Loss = 0.04765787720680237\n",
      "\n",
      "\n",
      "Currently on Epoch # 4000\n",
      "Training Loss = 0.0432356521487236\n",
      "\n",
      "\n",
      "Currently on Epoch # 5000\n",
      "Training Loss = 0.04803098738193512\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(init)\n",
    "    \n",
    "for i in range(epochs + 1):\n",
    "\n",
    "    for batch in Batching(Dirty_Trans, Clean_Trans, 128, shuffle = True):\n",
    "         batch_X , batch_Y = batch\n",
    "    \n",
    "         sess.run(train, feed_dict={X: batch_X, Y_true: batch_Y, hold_prob : 0.7})\n",
    "\n",
    "    if i% 1000 == 0:\n",
    "        loss = sess.run(MSE, feed_dict={X: batch_X, Y_true: batch_Y, hold_prob : 0.7})\n",
    "\n",
    "        #acc_tst, loss_tst = sess.run([accuracy, cross_entropy], feed_dict={X: mnist.test.images, Y_true: mnist.test.labels})\n",
    "\n",
    "        print(\"Currently on Epoch # {}\".format(i))\n",
    "        print(\"Training Loss = {}\".format(loss))\n",
    "        #print(\"Test Set Accuracy and Loss: Accuracy = {}, Loss = {}\".format(acc_tst*100, loss_tst*100))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the cleaned test signal back to audio signal\n",
    "\n",
    "Test Signal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_Clean_Trans = sess.run(Y_pred, feed_dict={X: T1_Dirty_Trans, hold_prob : 0.7})\n",
    "T1_Clean = np.transpose(T1_Clean_Trans)\n",
    "Phase = np.divide(T1, T1_mod)\n",
    "T1_Clean_Phase = np.multiply(T1_Clean,Phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_T1 = librosa.istft(T1_Clean_Phase,hop_length=512)\n",
    "librosa.output.write_wav('test_s_recons_01.wav', sh_T1, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Signal 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2_Clean_Trans = sess.run(Y_pred, feed_dict={X: T2_Dirty_Trans, hold_prob : 0.7})\n",
    "T2_Clean = np.transpose(T2_Clean_Trans)\n",
    "Phase = np.divide(T2, T2_mod)\n",
    "T2_Clean_Phase = np.multiply(T2_Clean,Phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_T2 = librosa.istft(T2_Clean_Phase,hop_length=512)\n",
    "librosa.output.write_wav('test_s_recons_02.wav', sh_T2, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
